{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tej/Documents/Courses/Learning/ML_With_PyTorch_Scikit_Practice/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://github.com/rasbt/\"\n",
    "\"machine-learning-book/raw/\"\n",
    "\"main/ch08/movie_data.csv.gz\")\n",
    "\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "with open(filename, \"wb\") as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)\n",
    "\n",
    "with gzip.open('movie_data.csv.gz', 'rb') as f_in:\n",
    "    with open('movie_data.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                                                   review  sentiment\n",
       "0      In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1      OK... so... I really like Kris Kristofferson a...          0\n",
       "2      ***SPOILER*** Do not read this, if you think a...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df.iloc[:35000]['review'].values\n",
    "train_labels = df.iloc[:35000]['sentiment'].values\n",
    "\n",
    "valid_texts = df.iloc[35000:40000]['review'].values\n",
    "valid_labels = df.iloc[35000:40000]['sentiment'].values\n",
    "\n",
    "test_texts = df.iloc[40000:]['review'].values\n",
    "test_labels = df.iloc[40000:]['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 199kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.07MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 4.69MB/s]\n",
      "config.json: 100%|██████████| 483/483 [00:00<00:00, 3.47MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    'distilbert-base-uncased'\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n",
    "test_encodings  = tokenizer(list(test_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx])\n",
    "            for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "valid_dataset = IMDbDataset(valid_encodings, valid_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 268M/268M [00:04<00:00, 59.9MB/s] \n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "'distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            ### Prepare data\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = \\\n",
    "            batch['attention_mask'].to(device)\n",
    "\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids,attention_mask=attention_mask)\n",
    "            \n",
    "            logits = outputs['logits']\n",
    "            \n",
    "            predicted_labels = torch.argmax(logits, 1)\n",
    "            num_examples += labels.size(0)\n",
    "            \n",
    "            correct_pred += \\\n",
    "            (predicted_labels == labels).sum()\n",
    "        return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0003 | Batch0000/2188 | Loss: 0.7000\n",
      "Epoch: 0001/0003 | Batch0250/2188 | Loss: 0.2762\n",
      "Epoch: 0001/0003 | Batch0500/2188 | Loss: 0.3582\n",
      "Epoch: 0001/0003 | Batch0750/2188 | Loss: 0.0129\n",
      "Epoch: 0001/0003 | Batch1000/2188 | Loss: 0.0873\n",
      "Epoch: 0001/0003 | Batch1250/2188 | Loss: 0.0143\n",
      "Epoch: 0001/0003 | Batch1500/2188 | Loss: 0.2263\n",
      "Epoch: 0001/0003 | Batch1750/2188 | Loss: 0.1311\n",
      "Epoch: 0001/0003 | Batch2000/2188 | Loss: 0.1856\n",
      "Training accuracy: 96.50%\n",
      "Valid accuracy: 92.02%\n",
      "Time elapsed: 12.61 min\n",
      "Epoch: 0002/0003 | Batch0000/2188 | Loss: 0.0497\n",
      "Epoch: 0002/0003 | Batch0250/2188 | Loss: 0.0840\n",
      "Epoch: 0002/0003 | Batch0500/2188 | Loss: 0.0934\n",
      "Epoch: 0002/0003 | Batch0750/2188 | Loss: 0.0089\n",
      "Epoch: 0002/0003 | Batch1000/2188 | Loss: 0.0790\n",
      "Epoch: 0002/0003 | Batch1250/2188 | Loss: 0.2908\n",
      "Epoch: 0002/0003 | Batch1500/2188 | Loss: 0.1807\n",
      "Epoch: 0002/0003 | Batch1750/2188 | Loss: 0.2112\n",
      "Epoch: 0002/0003 | Batch2000/2188 | Loss: 0.5125\n",
      "Training accuracy: 98.70%\n",
      "Valid accuracy: 92.18%\n",
      "Time elapsed: 25.18 min\n",
      "Epoch: 0003/0003 | Batch0000/2188 | Loss: 0.0881\n",
      "Epoch: 0003/0003 | Batch0250/2188 | Loss: 0.0008\n",
      "Epoch: 0003/0003 | Batch0500/2188 | Loss: 0.0040\n",
      "Epoch: 0003/0003 | Batch0750/2188 | Loss: 0.0062\n",
      "Epoch: 0003/0003 | Batch1000/2188 | Loss: 0.2052\n",
      "Epoch: 0003/0003 | Batch1250/2188 | Loss: 0.1935\n",
      "Epoch: 0003/0003 | Batch1500/2188 | Loss: 0.0014\n",
      "Epoch: 0003/0003 | Batch1750/2188 | Loss: 0.0132\n",
      "Epoch: 0003/0003 | Batch2000/2188 | Loss: 0.0877\n",
      "Training accuracy: 99.49%\n",
      "Valid accuracy: 92.38%\n",
      "Time elapsed: 37.66 min\n",
      "Total Training Time: 37.66 min\n",
      "Test accuracy: 92.52%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        ### Prepare data\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        \n",
    "        ### Forward pass\n",
    "        outputs = model(input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels)\n",
    "        loss, logits = outputs['loss'], outputs['logits']\n",
    "        \n",
    "        ### Backward pass\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        ### Logging\n",
    "        if not batch_idx % 250:\n",
    "            print(f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d}'\n",
    "            f' | Batch'\n",
    "            f'{batch_idx:04d}/'\n",
    "            f'{len(train_loader):04d} | '\n",
    "            f'Loss: {loss:.4f}')\n",
    "            model.eval()\n",
    "            \n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'Training accuracy: ' \\\n",
    "        f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "        f'\\nValid accuracy: ' \\\n",
    "        f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "\n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "\n",
    "\n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
